

parameters:
  num_classes: &num_classes 47
  input_dim: &input_dim 100


seed: 42

data_parameters:
  dataset_type: ogbn-products
  # transforms: 
  #   - "normalize_features"
  add_self_loops_and_remove_duplicate_edges: false
  remove_duplicate_edges: false
  train_data_loader_parameters:
    data_loader_type: optimized_random_node_loader
    num_parts: 1
    pin_memory: false
    on_device: true
  val_data_loader_parameters:
    data_loader_type: optimized_random_node_loader
    num_parts: 1
    pin_memory: false
    on_device: true
  test_data_loader_parameters:
    data_loader_type: optimized_random_node_loader
    num_parts: 1
    pin_memory: false
    on_device: true

model_parameters:
  task_type: node_classification
  architecture_parameters:
      architecture_type: sage
      input_dim: *input_dim
      hidden_dim: 200
      output_dim: *num_classes
      num_layers: 5
      dropout: 0.3
      use_input_projection: false
      use_output_projection: false
      use_residual: false
      use_layer_norm: true
      
  loss:
      loss_type: cross_entropy
      parameters:
        reduction: none

  metrics:
    - metric_type: optimized_accuracy
      display_name: accuracy
    - metric_type: optimized_f1
      display_name: f1
    - metric_type: optimized_precision
      display_name: precision
    - metric_type: optimized_recall
      display_name: recall

  optimizer:
    optimizer_type: adam
    parameters:
      lr: 0.001
      weight_decay: 0.0005

callbacks: 
    - callback_type: early_stopping
      parameters:
        monitor: val/loss
        patience: 30
        mode: min
    - callback_type: model_checkpoint
      parameters:
        monitor: val/loss
        mode: min
        save_top_k: 1
        filename: best

wandb_logger_parameters:
  reinit: true

compilation_parameters:
  use_compiled_torch: false
  full_graph: false

trainer_config:
  max_epochs: 200
  log_every_n_steps: 1
  # precision: bf16-mixed
  # profiler: simple

